{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "059be258",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Programs\\anaconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "581b22fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pickle_files/X.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_with_columns \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpickle_files/X.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m Z_with_columns \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpickle_files/Z.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m columns_to_drop \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mC:\\Programs\\anaconda3\\lib\\site-packages\\pandas\\io\\pickle.py:187\u001b[0m, in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m4    4    9\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m    186\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[1;32m--> 187\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    194\u001b[0m \n\u001b[0;32m    195\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Programs\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:798\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    790\u001b[0m             handle,\n\u001b[0;32m    791\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    794\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    795\u001b[0m         )\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    799\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    801\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pickle_files/X.pkl'"
     ]
    }
   ],
   "source": [
    "X_with_columns = pd.read_pickle(\"pickle_files/X.pkl\")\n",
    "Z_with_columns = pd.read_pickle(\"pickle_files/Z.pkl\")\n",
    "\n",
    "columns_to_drop = []\n",
    "\n",
    "X_with_columns.drop(columns_to_drop, axis = 1, inplace=True)\n",
    "Z_with_columns.drop(columns_to_drop, axis = 1, inplace=True)\n",
    "\n",
    "X = np.array(X_with_columns)\n",
    "Y = np.array(pd.read_pickle(\"pickle_files/Y.pkl\"))\n",
    "Z = np.array(Z_with_columns)\n",
    "df_next_games = pd.read_pickle(\"pickle_files/next_games.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3fa2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=4, random_state=0, shuffle=True)\n",
    "kf.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c47ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a38b09",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67577ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_model = xgb.XGBClassifier(silent=False, \n",
    "                      learning_rate=0.005,  \n",
    "                      colsample_bytree = 0.5,\n",
    "                      subsample = 0.8,\n",
    "                      objective='multi:softprob', \n",
    "                      n_estimators=1000, \n",
    "                      reg_alpha = 60,\n",
    "                      reg_lambda = .6,\n",
    "                      max_depth=5, \n",
    "                      max_delta_step=3,\n",
    "                      gamma=5,\n",
    "                      seed=82)\n",
    "\n",
    "# add max_delta_step=3  to handle imbalanced class with draws\n",
    "# max depth was 5. I changed to 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2882c7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "\n",
    "XGB_model.fit(X_train, y_train, eval_metric=[\"merror\", \"mlogloss\"], eval_set=eval_set, verbose=True)\n",
    "y_pred = XGB_model.predict(X_test)\n",
    "y_pred_train = XGB_model.predict(X_train)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f783ab59",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff53f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_pred).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02d6332",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc50fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(random_state = 42)\n",
    "LR.fit(X_train, y_train)\n",
    "LR_y_pred = LR.predict(X_test)\n",
    "LR_y_pred_train = LR.predict(X_train)\n",
    "LR_accuracy = accuracy_score(y_test, LR_y_pred)\n",
    "LR_accuracy_train = accuracy_score(y_train, LR_y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c8c526",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(LR_y_pred).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c416cec5",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ace6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"XGB train Accuracy: %.2f%%\" % (accuracy_train * 100.0))\n",
    "print(\"XGB Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print(\"LR train Accuracy: %.2f%%\" % (LR_accuracy_train * 100.0))\n",
    "print(\"LR Accuracy: %.2f%%\" % (LR_accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f927fd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_names = list(X_with_columns.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a329fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = np.round(XGB_model.feature_importances_,4)\n",
    "dictionary = dict(zip(features_names, importance))\n",
    "sorted_dictionary=sorted(dictionary.items(), key=lambda x:x[1], reverse=True)\n",
    "names=[]\n",
    "values=[]\n",
    "for i in range(0, len(importance)):\n",
    "    print('Feature Importance: {:35} {}%'.format(\n",
    "        sorted_dictionary[i][0], np.round(sorted_dictionary[i][1]*100,4))\n",
    "         )\n",
    "    names.append(sorted_dictionary[i][0])\n",
    "    values.append(np.round(sorted_dictionary[i][1]*100,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a297dbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_values = np.cumsum(values)\n",
    "values_over_95 = (cum_values > 95).sum()\n",
    "columns_over_95 = names[-values_over_95:]\n",
    "columns_over_95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ab36aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "#bottom, top = ylim()\n",
    "bottom = 0\n",
    "plt.plot(names,cum_values, '--bo', color='r')\n",
    "# set importance at 95%\n",
    "plt.axhline(95,color='black')\n",
    "plt.xticks(rotation=90);\n",
    "plt.xlabel('Feature'); \n",
    "plt.ylabel('Percentage'); \n",
    "plt.title('Cumulative Feature Importance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5c6ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, classes, labels,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    # Only use the labels that appear in the data\n",
    "    #classes = classes[unique_labels(y_true, y_pred)]\n",
    "    classes=classes\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    #plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             #rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e6f549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(y_test, y_pred, classes=pd.Series(Y).unique(), labels=pd.Series(Y).unique(),\n",
    "                      title='Confusion matrix, with normalization', normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff89848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def learning_curve(preds,y_test, model):\n",
    "    predictions = [round(value) for value in preds]\n",
    "    # evaluate predictions\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "    # retrieve performance metrics\n",
    "    results = model.evals_result()\n",
    "    epochs = len(results['validation_0']['merror'])\n",
    "    x_axis = range(0, epochs)\n",
    "    # plot log loss\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(x_axis, results['validation_0']['merror'], label='Train')\n",
    "    ax.plot(x_axis, results['validation_1']['merror'], label='Test')\n",
    "    ax.legend()\n",
    "    plt.ylabel('Log Loss')\n",
    "    plt.title('XGBoost Log Loss')\n",
    "    plt.show()\n",
    "    # plot classification error\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(x_axis, results['validation_0']['merror'], label='Train')\n",
    "    ax.plot(x_axis, results['validation_1']['merror'], label='Test')\n",
    "    ax.legend()\n",
    "    plt.ylabel('Classification Error')\n",
    "    plt.title('XGBoost Classification Error')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92927c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_curve(y_pred,y_test,XGB_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c128ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab96f1ec",
   "metadata": {},
   "source": [
    "## Predict Result for Next Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c341354",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_pred = XGB_model.predict(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada90323",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_df_next_games = df_next_games.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2105817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_df_next_games['predicted_result'] = z_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72457d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_df_next_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183bc3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    " z_pred_prob = XGB_model.predict_proba(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214a8bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_df_next_games['prob_loss'] = z_pred_prob[:,0]\n",
    "xgb_df_next_games['prob_draw'] = z_pred_prob[:,1]\n",
    "xgb_df_next_games['prob_win'] = z_pred_prob[:,2]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac539a22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7726871",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_df_next_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccb195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgb_df_next_games['home_prob_win'] = 0.0\n",
    "\n",
    "for i in range(len(xgb_df_next_games)):\n",
    "    if xgb_df_next_games['predicted_result'].values[i] == 3.0:\n",
    "        xgb_df_next_games['home_prob_win'].values[i] = xgb_df_next_games['prob_win'].values[i]\n",
    "    elif xgb_df_next_games['predicted_result'].values[i] == 2.0:\n",
    "        xgb_df_next_games['home_prob_win'].values[i] = 0.5\n",
    "    elif xgb_df_next_games['predicted_result'].values[i] == 1.0:\n",
    "        xgb_df_next_games['home_prob_win'].values[i] = 1.0 - xgb_df_next_games['prob_loss'].values[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84de0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_df_next_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccdf50d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef81e7a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
