{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee8f5d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn import feature_selection\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eee28264",
   "metadata": {},
   "outputs": [],
   "source": [
    "roundvar = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7df95382",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_afl_data(pred_round):\n",
    "    df_2017 = pd.read_csv(\"../data/afl_results_2017.csv\")\n",
    "    #print(df_2017.shape)\n",
    "    df_2018 = pd.read_csv(\"../data/afl_results_2018.csv\")\n",
    "    #print(df_2018.shape)\n",
    "    df_2019 = pd.read_csv(\"../data/afl_results_2019.csv\")\n",
    "    #print(df_2019.shape)\n",
    "    df_2020 = pd.read_csv(\"../data/afl_results_2020.csv\")\n",
    "    #print(df_2020.shape)\n",
    "    df_2021 = pd.read_csv(\"../data/afl_results_2021.csv\")\n",
    "    #print(df_2021.shape)\n",
    "    df_2022 = pd.read_csv(\"../data/afl_results_2022.csv\")\n",
    "    pred_round_results = df_2022[df_2022['round.roundNumber'] == pred_round]\n",
    "    df_2022 = df_2022[df_2022['round.roundNumber'] < pred_round]\n",
    "\n",
    "    #print(df_2022.shape)\n",
    "    df_all = pd.concat([df_2017, df_2018, df_2019, df_2020, df_2021,df_2022], axis=0)\n",
    "    df_all['Date'] = pd.to_datetime(df_all['match.date']).dt.strftime(\"%Y-%m-%d\")\n",
    "    df_players_2017 = pd.read_csv(\"../data/afl_players_stats_2017.csv\")\n",
    "    #print(df_players_2017.shape)\n",
    "    df_players_2018 = pd.read_csv(\"../data/afl_players_stats_2018.csv\")\n",
    "    #print(df_players_2018.shape)\n",
    "    df_players_2019 = pd.read_csv(\"../data/afl_players_stats_2019.csv\")\n",
    "    #print(df_players_2019.shape)\n",
    "    df_players_2020 = pd.read_csv(\"../data/afl_players_stats_2020.csv\")\n",
    "    #print(df_players_2020.shape)\n",
    "    df_players_2021 = pd.read_csv(\"../data/afl_players_stats_2021.csv\")\n",
    "    #print(df_players_2021.shape)\n",
    "    df_players_2022 = pd.read_csv(\"../data/afl_players_stats_2022.csv\")\n",
    "    df_players_2022 = df_players_2022[df_players_2022['Round'] < pred_round]\n",
    "\n",
    "    #print(df_players_2022.shape)\n",
    "    df_players = pd.concat([df_players_2017, df_players_2018, df_players_2019,df_players_2020,df_players_2021,df_players_2022], axis=0)\n",
    "    #print(df_players.shape)\n",
    "    #df_players.columns\n",
    "\n",
    "    df_fixture = pd.read_csv(\"../data/fixture_2022.csv\")\n",
    "    df_next_games_teams = df_fixture[(df_fixture['round.roundNumber'] == pred_round)]\n",
    "    df_next_games_teams = df_next_games_teams[['home.team.name','away.team.name','venue.name','compSeason.year','round.roundNumber']]\n",
    "    df_next_games_teams = df_next_games_teams.rename(columns={'home.team.name': 'match.homeTeam.name', 'away.team.name': 'match.awayTeam.name','compSeason.year':'round.year'})\n",
    "    df_next_games_teams['match.matchId'] = np.arange(len(df_next_games_teams))\n",
    "\n",
    "    return df_all, df_players, df_fixture, df_next_games_teams, pred_round_results\n",
    "\n",
    "def get_aggregate_player_stats(df=None):\n",
    "\n",
    "    agg_stats = (df.rename(columns={ # Rename columns to lowercase\n",
    "                    'Home.team': 'match.homeTeam.name',\n",
    "                    'Away.team': 'match.awayTeam.name',\n",
    "                    })\n",
    "                   .groupby(by=['Date', 'Season', 'match.homeTeam.name', 'match.awayTeam.name'], as_index=False) # Groupby to aggregate the stats for each game\n",
    "                   .sum()\n",
    "                   #.drop(columns=['DE', 'TOG', 'Match_id']) # Drop columns\n",
    "                   .assign(date=lambda df: pd.to_datetime(df.Date, format=\"%Y-%m-%d\")) # Create a datetime object\n",
    "                   .sort_values(by='Date')\n",
    "                   .reset_index(drop=True))\n",
    "    return agg_stats\n",
    "\n",
    "\n",
    "df_all, df_players, df_fixture, df_next_games_teams, pred_round_results = load_afl_data(roundvar)\n",
    "\n",
    "agg_player = get_aggregate_player_stats(df_players)\n",
    "afl_df = df_all.merge(agg_player, on=['Date', 'match.homeTeam.name', 'match.awayTeam.name'], how='left')\n",
    "\n",
    "# Add average goal diff for home and away team rolling 4 games\n",
    "\n",
    "afl_df['HTGDIFF'] = afl_df['homeTeamScore.matchScore.goals'] - afl_df['awayTeamScore.matchScore.goals']\n",
    "afl_df['ATGDIFF'] = afl_df['awayTeamScore.matchScore.goals'] - afl_df['homeTeamScore.matchScore.goals']\n",
    "\n",
    "def from_dict_value_to_df(d):\n",
    "    \"\"\"\n",
    "    input = dictionary \n",
    "    output = dataframe as part of all the values from the dictionary\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    for v in d.values():\n",
    "        df = pd.concat([df,v])\n",
    "    return df\n",
    "\n",
    "def avg_goal_diff(df, avg_h_a_diff, a_h_team, a_h_goal_letter):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        df = dataframe with all results\n",
    "        avg_h_a_diff = name of the new column\n",
    "        a_h_team = HomeTeam or AwayTeam\n",
    "        a_h_goal_letter = 'H' for home or 'A' for away\n",
    "    output: \n",
    "        avg_per_team = dictionary with with team as key and columns as values with new column H/ATGDIFF\n",
    "    \"\"\"\n",
    "    df[avg_h_a_diff] = 0\n",
    "    avg_per_team = {}\n",
    "    all_teams = df[a_h_team].unique()\n",
    "    for t in all_teams:\n",
    "        df_team = df[df[a_h_team]==t].fillna(0)\n",
    "        result = df_team['{}TGDIFF'.format(a_h_goal_letter)].rolling(4).mean()\n",
    "        df_team[avg_h_a_diff] = result\n",
    "        avg_per_team[t] = df_team\n",
    "    return avg_per_team\n",
    "\n",
    "d_AVGFTHG = avg_goal_diff(afl_df, 'AVGHTGDIFF', 'match.homeTeam.name', 'H')\n",
    "df_AVGFTHG = from_dict_value_to_df(d_AVGFTHG)\n",
    "df_AVGFTHG.sort_index(inplace=True)\n",
    "d_AVGFTAG = avg_goal_diff(df_AVGFTHG, 'AVGATGDIFF', 'match.awayTeam.name', 'A')\n",
    "afl_df = from_dict_value_to_df(d_AVGFTAG)\n",
    "afl_df.sort_index(inplace=True)\n",
    "afl_df['AVGATGDIFF'].fillna(0, inplace=True)\n",
    "\n",
    "afl_df['goal_diff'] = afl_df['homeTeamScore.matchScore.goals'] - afl_df['awayTeamScore.matchScore.goals']\n",
    "\n",
    "for index, row in df_all[df_all['match.status']=='CONCLUDED'].iterrows():\n",
    "    if afl_df['goal_diff'][index] > 0:\n",
    "        afl_df.at[index,'result'] = 1   # 1 is a win\n",
    "    else:\n",
    "        afl_df.at[index,'result'] = 0  # 0 is a loss \n",
    "\n",
    "def previous_data(df, h_or_a_team, column, letter, past_n):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        df = dataframe with all results\n",
    "        a_h_team = HomeTeam or AwayTeam\n",
    "        column = column selected to get previous data from\n",
    "    output:\n",
    "        team_with_past_dict = dictionary with team as a key and columns as values with new \n",
    "                              columns with past value\n",
    "    \"\"\"\n",
    "    d = dict()\n",
    "    team_with_past_dict = dict()\n",
    "    all_teams = df[h_or_a_team].unique()\n",
    "    for team in all_teams:\n",
    "        n_games = len(df[df[h_or_a_team]==team])\n",
    "        team_with_past_dict[team] = df[df[h_or_a_team]==team]\n",
    "        for i in range(1, past_n):\n",
    "            d[i] = team_with_past_dict[team].assign(\n",
    "                result=team_with_past_dict[team].groupby(h_or_a_team)[column].shift(i)\n",
    "            ).fillna({'{}_X'.format(column): 0})\n",
    "            team_with_past_dict[team]['{}_{}_{}'.format(letter, column, i)] = d[i].result\n",
    "    return team_with_past_dict\n",
    "\n",
    "def previous_data_call(df, side, column, letter, iterations):\n",
    "    d = previous_data(df, side, column, letter, iterations)\n",
    "    df_result= from_dict_value_to_df(d)\n",
    "    df_result.sort_index(inplace=True)\n",
    "    return df_result\n",
    "\n",
    "df_last_home_results = previous_data_call(afl_df, 'match.homeTeam.name', 'result', 'H', 3)\n",
    "df_last_away_results = previous_data_call(df_last_home_results, 'match.awayTeam.name', 'result', 'A', 3)\n",
    "df_last_last_HTGDIFF_results = previous_data_call(df_last_away_results, 'match.homeTeam.name', 'HTGDIFF', 'H', 3)\n",
    "df_last_last_ATGDIFF_results = previous_data_call(df_last_last_HTGDIFF_results, 'match.awayTeam.name', 'ATGDIFF', 'A', 3)\n",
    "df_last_AVGFTHG_results = previous_data_call(df_last_last_ATGDIFF_results, 'match.homeTeam.name', 'AVGHTGDIFF', 'H', 2)\n",
    "df_last_AVGFTAG_results = previous_data_call(df_last_AVGFTHG_results, 'match.awayTeam.name', 'AVGATGDIFF', 'A', 2)\n",
    "afl_df = df_last_AVGFTAG_results.copy()\n",
    "\n",
    "all_cols = ['match.matchId','match.date', 'match.status', 'match.venue', 'match.homeTeam.name', 'match.awayTeam.name','venue.name', 'venue.state', 'round.name', 'round.year', 'round.roundNumber', 'status',\n",
    "'homeTeamScore.rushedBehinds', 'homeTeamScore.minutesInFront',\n",
    "       'homeTeamScore.matchScore.totalScore', 'homeTeamScore.matchScore.goals',\n",
    "       'homeTeamScore.matchScore.behinds',\n",
    "       'homeTeamScore.matchScore.superGoals', 'awayTeamScore.rushedBehinds',\n",
    "       'awayTeamScore.minutesInFront', 'awayTeamScore.matchScore.totalScore',\n",
    "       'awayTeamScore.matchScore.goals', 'awayTeamScore.matchScore.behinds',\n",
    "       'awayTeamScore.matchScore.superGoals', 'weather.tempInCelsius',\n",
    "       'homeTeamScoreChart.goals', 'homeTeamScoreChart.leftBehinds',\n",
    "       'homeTeamScoreChart.rightBehinds', 'homeTeamScoreChart.leftPosters',\n",
    "       'homeTeamScoreChart.rightPosters', 'homeTeamScoreChart.rushedBehinds',\n",
    "       'homeTeamScoreChart.touchedBehinds', 'awayTeamScoreChart.goals',\n",
    "       'awayTeamScoreChart.leftBehinds', 'awayTeamScoreChart.rightBehinds',\n",
    "       'awayTeamScoreChart.leftPosters', 'awayTeamScoreChart.rightPosters',\n",
    "       'awayTeamScoreChart.rushedBehinds', 'awayTeamScoreChart.touchedBehinds', \n",
    "       'HQ1G', 'HQ1B', 'HQ2G',\n",
    "       'HQ2B', 'HQ3G', 'HQ3B', 'HQ4G', 'HQ4B', 'Home.score', 'AQ1G', 'AQ1B',\n",
    "       'AQ2G', 'AQ2B', 'AQ3G', 'AQ3B', 'AQ4G', 'AQ4B', 'Away.score',\n",
    "       'Kicks', 'Marks', 'Handballs', 'Goals', 'Behinds', 'Hit.Outs',\n",
    "       'Tackles', 'Rebounds', 'Inside.50s', 'Clearances', 'Clangers',\n",
    "       'Frees.For', 'Frees.Against', 'Brownlow.Votes', 'Contested.Possessions',\n",
    "       'Uncontested.Possessions', 'Contested.Marks', 'Marks.Inside.50',\n",
    "       'One.Percenters', 'Bounces', 'Goal.Assists', 'Time.on.Ground..',\n",
    "       'Substitute', 'group_id', 'HTGDIFF', 'ATGDIFF', 'AVGHTGDIFF',\n",
    "       'AVGATGDIFF', 'goal_diff', 'result', 'H_result_1', 'H_result_2',\n",
    "       'A_result_1', 'A_result_2', 'H_HTGDIFF_1', 'H_HTGDIFF_2', 'A_ATGDIFF_1',\n",
    "       'A_ATGDIFF_2', 'H_AVGHTGDIFF_1', 'A_AVGATGDIFF_1']\n",
    "\n",
    "non_feature_cols = ['match.matchId','match.date', 'match.status', 'match.venue', 'match.homeTeam.name', 'match.awayTeam.name','venue.name', 'venue.state', 'round.name', 'round.year', 'round.roundNumber', 'status','Season']\n",
    "feature_cols = [\n",
    "       'homeTeamScore.rushedBehinds', 'homeTeamScore.minutesInFront',\n",
    "       'homeTeamScore.matchScore.totalScore', 'homeTeamScore.matchScore.goals',\n",
    "       'homeTeamScore.matchScore.behinds',\n",
    "       'homeTeamScore.matchScore.superGoals', 'awayTeamScore.rushedBehinds',\n",
    "       'awayTeamScore.minutesInFront', 'awayTeamScore.matchScore.totalScore',\n",
    "       'awayTeamScore.matchScore.goals', 'awayTeamScore.matchScore.behinds',\n",
    "       'awayTeamScore.matchScore.superGoals', 'weather.tempInCelsius',\n",
    "       'homeTeamScoreChart.goals', 'homeTeamScoreChart.leftBehinds',\n",
    "       'homeTeamScoreChart.rightBehinds', 'homeTeamScoreChart.leftPosters',\n",
    "       'homeTeamScoreChart.rightPosters', 'homeTeamScoreChart.rushedBehinds',\n",
    "       'homeTeamScoreChart.touchedBehinds', 'awayTeamScoreChart.goals',\n",
    "       'awayTeamScoreChart.leftBehinds', 'awayTeamScoreChart.rightBehinds',\n",
    "       'awayTeamScoreChart.leftPosters', 'awayTeamScoreChart.rightPosters',\n",
    "       'awayTeamScoreChart.rushedBehinds', 'awayTeamScoreChart.touchedBehinds', \n",
    "       'HQ1G', 'HQ1B', 'HQ2G',\n",
    "       'HQ2B', 'HQ3G', 'HQ3B', 'HQ4G', 'HQ4B', 'Home.score', 'AQ1G', 'AQ1B',\n",
    "       'AQ2G', 'AQ2B', 'AQ3G', 'AQ3B', 'AQ4G', 'AQ4B', 'Away.score',\n",
    "       'Kicks', 'Marks', 'Handballs', 'Goals', 'Behinds', 'Hit.Outs',\n",
    "       'Tackles', 'Rebounds', 'Inside.50s', 'Clearances', 'Clangers',\n",
    "       'Frees.For', 'Frees.Against', 'Brownlow.Votes', 'Contested.Possessions',\n",
    "       'Uncontested.Possessions', 'Contested.Marks', 'Marks.Inside.50',\n",
    "       'One.Percenters', 'Bounces', 'Goal.Assists', 'Time.on.Ground..',\n",
    "       'Substitute', 'group_id', 'HTGDIFF', 'ATGDIFF', 'AVGHTGDIFF',\n",
    "       'AVGATGDIFF', 'goal_diff', 'result', 'H_result_1', 'H_result_2',\n",
    "       'A_result_1', 'A_result_2', 'H_HTGDIFF_1', 'H_HTGDIFF_2', 'A_ATGDIFF_1',\n",
    "       'A_ATGDIFF_2', 'H_AVGHTGDIFF_1', 'A_AVGATGDIFF_1']\n",
    "\n",
    "afl_df = afl_df[all_cols] \n",
    "\n",
    "afl_df = afl_df.rename(columns={col: 'f_' + col for col in afl_df if col not in non_feature_cols})\n",
    "\n",
    "\n",
    "\n",
    "def create_training_and_test_data(afl_df,df_next_games_teams):\n",
    "\n",
    "    # Define a function which returns a DataFrame with the expontential moving average for each numeric stat\n",
    "    def create_exp_weighted_avgs(df, span):\n",
    "        # Create a copy of the df with only the game id and the team - we will add cols to this df\n",
    "        ema_features = df[['match.matchId', 'match.homeTeam.name']].copy()\n",
    "\n",
    "        feature_names = [col for col in df.columns if col.startswith('f_')] # Get a list of columns we will iterate over\n",
    "\n",
    "        for feature_name in feature_names:\n",
    "            feature_ema = (df.groupby('match.homeTeam.name')[feature_name]\n",
    "                             .transform(lambda row: (row.ewm(span=span)\n",
    "                                                        .mean()\n",
    "                                                        .shift(1))))\n",
    "            ema_features[feature_name] = feature_ema\n",
    "\n",
    "        return ema_features\n",
    "\n",
    "        # Define a function which finds the elo for each team in each game and returns a dictionary with the game ID as a key and the\n",
    "    # elos as the key's value, in a list. It also outputs the probabilities and a dictionary of the final elos for each team\n",
    "    def elo_applier(df, k_factor):\n",
    "        # Initialise a dictionary with default elos for each team\n",
    "        elo_dict = {team: 1500 for team in df['match.homeTeam.name'].unique()}\n",
    "        elos, elo_probs = {}, {}\n",
    "\n",
    "        # Loop over the rows in the DataFrame\n",
    "        for index, row in df.iterrows():\n",
    "            # Get the Game ID\n",
    "            game_id = row['match.matchId']\n",
    "\n",
    "            # Get the margin\n",
    "            margin = row['f_goal_diff']\n",
    "\n",
    "            # If the game already has the elos for the home and away team in the elos dictionary, go to the next game\n",
    "            if game_id in elos.keys():\n",
    "                continue\n",
    "\n",
    "            # Get the team and opposition\n",
    "            home_team = row['match.homeTeam.name']\n",
    "            away_team = row['match.awayTeam.name']\n",
    "\n",
    "            # Get the team and opposition elo score\n",
    "            home_team_elo = elo_dict[home_team]\n",
    "            away_team_elo = elo_dict[away_team]\n",
    "\n",
    "            # Calculated the probability of winning for the team and opposition\n",
    "            prob_win_home = 1 / (1 + 10**((away_team_elo - home_team_elo) / 400))\n",
    "            prob_win_away = 1 - prob_win_home\n",
    "\n",
    "            # Add the elos and probabilities our elos dictionary and elo_probs dictionary based on the Game ID\n",
    "            elos[game_id] = [home_team_elo, away_team_elo]\n",
    "            elo_probs[game_id] = [prob_win_home, prob_win_away]\n",
    "\n",
    "            # Calculate the new elos of each team\n",
    "            if margin > 0: # Home team wins; update both teams' elo\n",
    "                new_home_team_elo = home_team_elo + k_factor*(1 - prob_win_home)\n",
    "                new_away_team_elo = away_team_elo + k_factor*(0 - prob_win_away)\n",
    "            elif margin < 0: # Away team wins; update both teams' elo\n",
    "                new_home_team_elo = home_team_elo + k_factor*(0 - prob_win_home)\n",
    "                new_away_team_elo = away_team_elo + k_factor*(1 - prob_win_away)\n",
    "            elif margin == 0: # Drawn game' update both teams' elo\n",
    "                new_home_team_elo = home_team_elo + k_factor*(0.5 - prob_win_home)\n",
    "                new_away_team_elo = away_team_elo + k_factor*(0.5 - prob_win_away)\n",
    "\n",
    "            # Update elos in elo dictionary\n",
    "            elo_dict[home_team] = new_home_team_elo\n",
    "            elo_dict[away_team] = new_away_team_elo\n",
    "\n",
    "        return elos, elo_probs, elo_dict\n",
    "\n",
    "    afl_df['train_data'] = 1\n",
    "    df_next_games_teams['train_data'] = 0\n",
    "\n",
    "    afl_data = afl_df.append(df_next_games_teams).reset_index(drop=True)\n",
    "\n",
    "    features_rolling_averages = create_exp_weighted_avgs(afl_data, span=10)\n",
    "\n",
    "    features = afl_data[['match.date', 'match.matchId', 'match.homeTeam.name', 'match.awayTeam.name', 'venue.name','round.year','train_data']].copy()\n",
    "    features = pd.merge(features, features_rolling_averages, on=['match.matchId', 'match.homeTeam.name'])\n",
    "\n",
    "    form_btwn_teams = afl_df[['match.matchId', 'match.homeTeam.name', 'match.awayTeam.name', 'f_goal_diff']].copy()\n",
    "\n",
    "\n",
    "    elos, elo_probs, elo_dict = elo_applier(afl_data, 30)\n",
    "    # Add our created features - elo, efficiency etc.\n",
    "\n",
    "    features = (features.assign(f_elo_home=lambda df: df['match.matchId'].map(elos).apply(lambda x: x[0]),\n",
    "                                                f_elo_away=lambda df: df['match.matchId'].map(elos).apply(lambda x: x[1]))\n",
    "                                          .reset_index(drop=True))\n",
    "\n",
    "#    form_btwn_teams_inv = pd.DataFrame()\n",
    "\n",
    "#    for index, row in form_btwn_teams.iterrows():\n",
    "#        home = row['match.homeTeam.name']\n",
    "#        away = row['match.awayTeam.name']\n",
    "#        matchid = row['match.matchId']\n",
    "#        margin = row['f_goal_diff']\n",
    "\n",
    "#        form_btwn_teams_inv = form_btwn_teams_inv.append({'match.matchId': matchid, 'match.homeTeam.name': away, 'match.awayTeam.name': home, 'f_goal_diff': -1*margin}, ignore_index=True)\n",
    "\n",
    "#    form_btwn_teams['f_form_margin_btwn_teams'] = (form_btwn_teams.groupby(['match.homeTeam.name', 'match.awayTeam.name'])['f_goal_diff']\n",
    "#                                                              .transform(lambda row: row.rolling(5).mean().shift())\n",
    "#                                                              .fillna(0))\n",
    "\n",
    "#    form_btwn_teams['f_form_past_5_btwn_teams'] = \\\n",
    "#    (form_btwn_teams.assign(win=lambda df: df.apply(lambda row: 1 if row.f_goal_diff > 0 else 0, axis='columns'))\n",
    "#                  .groupby(['match.homeTeam.name', 'match.awayTeam.name'])['win']\n",
    "#                  .transform(lambda row: row.rolling(5).mean().shift() * 5)\n",
    "#                  .fillna(0))\n",
    "\n",
    "\n",
    "    #print(features.shape)\n",
    "    # Merge to our features df\n",
    "    #features = pd.merge(features, form_btwn_teams_1.drop(columns=['f_goal_diff']), on=['match.matchId', 'match.homeTeam.name', 'match.awayTeam.name'])\n",
    "    #print(features.shape)\n",
    "\n",
    "    # Get the result and merge to the feature_df\n",
    "\n",
    "    match_results = (afl_df.assign(result=lambda df: df.apply(lambda row: 1 if row['f_goal_diff'] > 0 else 0, axis=1)))\n",
    "    # Merge result column to feature_df\n",
    "    feature_df = pd.merge(features, match_results[['match.matchId', 'result']], on='match.matchId')\n",
    "\n",
    "    return feature_df,features_rolling_averages, afl_data, features\n",
    "\n",
    "feature_df, features_rolling_averages, afl_data, features = create_training_and_test_data(afl_df,df_next_games_teams)\n",
    "feature_columns = [col for col in feature_df if col.startswith('f_')]\n",
    "features['f_elo_home'] = features['f_elo_home']/1500\n",
    "features['f_elo_away'] = features['f_elo_away']/1500\n",
    "\n",
    "# Build model from feature_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deec9827",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = feature_df.dropna()\n",
    "\n",
    "all_X = feature_df.loc[:, feature_columns]\n",
    "all_y = feature_df.loc[:, 'result']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_X, all_y, test_size=0.3, random_state=42, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cb4ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb72559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc721a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e3856fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train[feature_columns] = scaler.fit_transform(X_train[feature_columns])\n",
    "X_test[feature_columns] = scaler.transform(X_test[feature_columns])\n",
    "\n",
    "# Create a list of standard classifiers\n",
    "classifiers = [\n",
    "    #Ensemble Methods\n",
    "    ensemble.AdaBoostClassifier(),\n",
    "    ensemble.BaggingClassifier(),\n",
    "    ensemble.ExtraTreesClassifier(),\n",
    "    ensemble.GradientBoostingClassifier(),\n",
    "    ensemble.RandomForestClassifier(),\n",
    "\n",
    "    #Gaussian Processes\n",
    "    gaussian_process.GaussianProcessClassifier(),\n",
    "\n",
    "    #GLM\n",
    "    linear_model.LogisticRegressionCV(),\n",
    "    \n",
    "    #Navies Bayes\n",
    "    naive_bayes.BernoulliNB(),\n",
    "    naive_bayes.GaussianNB(),\n",
    "\n",
    "    #SVM\n",
    "    svm.SVC(probability=True),\n",
    "    svm.NuSVC(probability=True),\n",
    "\n",
    "    #Discriminant Analysis\n",
    "    discriminant_analysis.LinearDiscriminantAnalysis(),\n",
    "    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
    "\n",
    "\n",
    "    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n",
    "    #XGBClassifier()    \n",
    "]\n",
    "\n",
    "def new_scorer(y,y_pred):\n",
    "   \n",
    "    xx = pd.DataFrame({'y':list(y),'y_pred': list(y_pred)}, columns=['y','y_pred'])     \n",
    "    xx.loc[xx['y'].astype(int)==0,'actual_score']= 1+np.log2(1-xx['y_pred'].astype(float))\n",
    "    xx.loc[xx['y'].astype(int)==1,'actual_score']= 1+np.log2(xx['y_pred'].astype(float))\n",
    "\n",
    "    return np.mean(xx['actual_score'])\n",
    "\n",
    "\n",
    "# Define a functiom which finds the best algorithms for our modelling task\n",
    "def find_best_algorithms(classifier_list, X, y):\n",
    "    # This function is adapted from https://www.kaggle.com/yassineghouzam/titanic-top-4-with-ensemble-modeling\n",
    "    # Cross validate model with Kfold stratified cross validation\n",
    "    kfold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "    # Grab the cross validation scores for each algorithm\n",
    "    #cv_results = [cross_val_score(classifier, X, y, scoring = \"neg_log_loss\", cv = kfold) for classifier in classifier_list]\n",
    "    cv_results = [cross_val_score(classifier, X, y, scoring = new_scorer, cv = kfold) for classifier in classifier_list]\n",
    "    cv_means = [cv_result.mean() * -1 for cv_result in cv_results]\n",
    "    cv_std = [cv_result.std() for cv_result in cv_results]\n",
    "    algorithm_names = [alg.__class__.__name__ for alg in classifiers]\n",
    "\n",
    "    # Create a DataFrame of all the CV results\n",
    "    cv_results = pd.DataFrame({\n",
    "        \"Mean Log Loss\": cv_means,\n",
    "        \"Log Loss Std\": cv_std,\n",
    "        \"Algorithm\": algorithm_names\n",
    "    })\n",
    "\n",
    "\n",
    "    return cv_results.sort_values(by='Mean Log Loss').reset_index(drop=True)\n",
    "\n",
    "best_algos = find_best_algorithms(classifiers, X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89695c70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c437431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ad9b50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "689d2e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Log Loss</th>\n",
       "      <th>Log Loss Std</th>\n",
       "      <th>Algorithm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BernoulliNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GaussianNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NuSVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Mean Log Loss  Log Loss Std                      Algorithm\n",
       "0             NaN           NaN             AdaBoostClassifier\n",
       "1             NaN           NaN              BaggingClassifier\n",
       "2             NaN           NaN           ExtraTreesClassifier\n",
       "3             NaN           NaN     GradientBoostingClassifier\n",
       "4             NaN           NaN         RandomForestClassifier\n",
       "5             NaN           NaN      GaussianProcessClassifier\n",
       "6             NaN           NaN           LogisticRegressionCV\n",
       "7             NaN           NaN                    BernoulliNB\n",
       "8             NaN           NaN                     GaussianNB\n",
       "9             NaN           NaN                            SVC\n",
       "10            NaN           NaN                          NuSVC\n",
       "11            NaN           NaN     LinearDiscriminantAnalysis\n",
       "12            NaN           NaN  QuadraticDiscriminantAnalysis"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59685fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n"
     ]
    }
   ],
   "source": [
    "# Define a function which optimises the hyperparameters of our chosen algorithms\n",
    "def optimise_hyperparameters(train_x, train_y, algorithms, parameters):\n",
    "    kfold = StratifiedKFold(n_splits=5)\n",
    "    best_estimators = []\n",
    "\n",
    "    for alg, params in zip(algorithms, parameters):\n",
    "        #gs = GridSearchCV(alg, param_grid=params, cv=kfold, scoring='neg_log_loss', verbose=1)\n",
    "        gs = GridSearchCV(alg, param_grid=params, cv=kfold, scoring=new_scorer, verbose=1)\n",
    "        gs.fit(train_x, train_y)\n",
    "        best_estimators.append(gs.best_estimator_)\n",
    "    return best_estimators\n",
    "\n",
    "# Define our parameters to run a grid search over\n",
    "lr_grid = {\n",
    "    \"C\": [0.0001, 0.001, 0.01, 0.05, 0.2, 0.5, 1.0],\n",
    "    \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\"]\n",
    "}\n",
    "\n",
    "# Add our algorithms and parameters to lists to be used in our function\n",
    "alg_list = [linear_model.LogisticRegression(), ensemble.RandomForestClassifier()]\n",
    "param_list = [lr_grid]\n",
    "\n",
    "# Find the best estimators, then add our other estimators which don't need optimisation\n",
    "best_estimators = optimise_hyperparameters(X_train, y_train, alg_list, param_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0439d7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogisticRegression(C=0.0001, solver='newton-cg')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffeb4f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['C', 'break_ties', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.SVC(probability=True).get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5131aafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bootstrap', 'ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'max_samples', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'n_estimators', 'n_jobs', 'oob_score', 'random_state', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.RandomForestClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad5cbcdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Cs', 'class_weight', 'cv', 'dual', 'fit_intercept', 'intercept_scaling', 'l1_ratios', 'max_iter', 'multi_class', 'n_jobs', 'penalty', 'random_state', 'refit', 'scoring', 'solver', 'tol', 'verbose'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.LogisticRegressionCV().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c72002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_best_params = best_estimators[0].get_params()\n",
    "\n",
    "lr = LogisticRegression(C=0.01, solver='liblinear') # **lr_best_params\n",
    "#lr = LogisticRegression(**lr_best_params) # **lr_best_params\n",
    "lr.fit(X_train, y_train)\n",
    "final_predictions_lr = lr.predict(X_test)\n",
    "accuracy = (final_predictions_lr == y_test).mean() * 100\n",
    "score = new_scorer(final_predictions_lr,y_test)\n",
    "#svc = svm.SVC(probability=True)\n",
    "#svc.fit(X_train, y_train)\n",
    "#final_predictions_svc = svc.predict(X_test)\n",
    "#accuracy = (final_predictions_svc == y_test).mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91fe67ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.16838487972509\n",
      "-inf\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86ad34a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: -0.00497\n",
      "Feature: 1, Score: -0.00582\n",
      "Feature: 2, Score: 0.00418\n",
      "Feature: 3, Score: 0.00138\n",
      "Feature: 4, Score: 0.02184\n",
      "Feature: 5, Score: 0.00000\n",
      "Feature: 6, Score: 0.02952\n",
      "Feature: 7, Score: 0.01917\n",
      "Feature: 8, Score: 0.00917\n",
      "Feature: 9, Score: 0.01780\n",
      "Feature: 10, Score: -0.05279\n",
      "Feature: 11, Score: 0.00000\n",
      "Feature: 12, Score: -0.03058\n",
      "Feature: 13, Score: 0.00138\n",
      "Feature: 14, Score: -0.00747\n",
      "Feature: 15, Score: 0.04714\n",
      "Feature: 16, Score: -0.00159\n",
      "Feature: 17, Score: 0.02684\n",
      "Feature: 18, Score: -0.00497\n",
      "Feature: 19, Score: -0.00020\n",
      "Feature: 20, Score: 0.01780\n",
      "Feature: 21, Score: 0.01646\n",
      "Feature: 22, Score: -0.08543\n",
      "Feature: 23, Score: -0.08857\n",
      "Feature: 24, Score: -0.07912\n",
      "Feature: 25, Score: 0.02952\n",
      "Feature: 26, Score: -0.03240\n",
      "Feature: 27, Score: 0.03687\n",
      "Feature: 28, Score: -0.00197\n",
      "Feature: 29, Score: -0.00113\n",
      "Feature: 30, Score: 0.02244\n",
      "Feature: 31, Score: -0.02503\n",
      "Feature: 32, Score: 0.01162\n",
      "Feature: 33, Score: -0.01079\n",
      "Feature: 34, Score: 0.01911\n",
      "Feature: 35, Score: -0.00675\n",
      "Feature: 36, Score: -0.02255\n",
      "Feature: 37, Score: -0.06451\n",
      "Feature: 38, Score: -0.02623\n",
      "Feature: 39, Score: -0.03008\n",
      "Feature: 40, Score: -0.01301\n",
      "Feature: 41, Score: -0.01572\n",
      "Feature: 42, Score: 0.01172\n",
      "Feature: 43, Score: -0.00536\n",
      "Feature: 44, Score: 0.00964\n",
      "Feature: 45, Score: -0.00446\n",
      "Feature: 46, Score: 0.00485\n",
      "Feature: 47, Score: -0.01225\n",
      "Feature: 48, Score: 0.00032\n",
      "Feature: 49, Score: 0.00686\n",
      "Feature: 50, Score: -0.00527\n",
      "Feature: 51, Score: -0.02600\n",
      "Feature: 52, Score: -0.00296\n",
      "Feature: 53, Score: -0.00297\n",
      "Feature: 54, Score: -0.00261\n",
      "Feature: 55, Score: 0.00842\n",
      "Feature: 56, Score: 0.00088\n",
      "Feature: 57, Score: 0.00075\n",
      "Feature: 58, Score: 0.00962\n",
      "Feature: 59, Score: -0.00613\n",
      "Feature: 60, Score: -0.00983\n",
      "Feature: 61, Score: 0.03379\n",
      "Feature: 62, Score: 0.01623\n",
      "Feature: 63, Score: -0.00855\n",
      "Feature: 64, Score: -0.01072\n",
      "Feature: 65, Score: -0.00351\n",
      "Feature: 66, Score: 0.00180\n",
      "Feature: 67, Score: 0.00000\n",
      "Feature: 68, Score: 0.00000\n",
      "Feature: 69, Score: -0.01077\n",
      "Feature: 70, Score: 0.01077\n",
      "Feature: 71, Score: 0.06781\n",
      "Feature: 72, Score: -0.01454\n",
      "Feature: 73, Score: -0.01077\n",
      "Feature: 74, Score: -0.03479\n",
      "Feature: 75, Score: 0.07276\n",
      "Feature: 76, Score: -0.00882\n",
      "Feature: 77, Score: 0.00028\n",
      "Feature: 78, Score: 0.09696\n",
      "Feature: 79, Score: 0.03113\n",
      "Feature: 80, Score: 0.00661\n",
      "Feature: 81, Score: 0.02970\n",
      "Feature: 82, Score: -0.04282\n",
      "Feature: 83, Score: 0.07056\n",
      "Feature: 84, Score: 0.09076\n",
      "Feature: 85, Score: 0.17018\n",
      "Feature: 86, Score: -0.23769\n"
     ]
    }
   ],
   "source": [
    "importance = lr.coef_[0]\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "#pyplot.bar([x for x in range(len(importance))], importance)\n",
    "#pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc086aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f_Goal.Assists'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns[65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b3c1b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de80aa78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c27df277",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "next_round_features = features[features['train_data']==0][feature_columns]\n",
    "\n",
    "next_round_predictions = lr.predict(next_round_features)\n",
    "\n",
    "prediction_probs = lr.predict_proba(next_round_features)\n",
    "\n",
    "df_next_games_teams['pred_home_result'] =  next_round_predictions\n",
    "df_next_games_teams['pred_home_prob'] = prediction_probs[:,1].round(3)\n",
    "\n",
    "df_next_games_teams['enter_tips'] = ''\n",
    "for i in range(len(df_next_games_teams)):\n",
    "    pred_home_result = df_next_games_teams['pred_home_result'].values[i]\n",
    "\n",
    "    if pred_home_result == 1:\n",
    "        entertips = 'pick %s with p=%s' %(df_next_games_teams['match.homeTeam.name'].values[i],df_next_games_teams['pred_home_prob'].values[i])\n",
    "        df_next_games_teams['enter_tips'].values[i] = entertips\n",
    "    else:\n",
    "        entertips = 'pick %s with p=%s' % (df_next_games_teams['match.awayTeam.name'].values[i],1-df_next_games_teams['pred_home_prob'].values[i])\n",
    "        df_next_games_teams['enter_tips'].values[i] = entertips\n",
    "\n",
    "\n",
    "\n",
    "#if len(pred_round_results)==0:\n",
    "#    return accuracy, df_next_games_teams, features, afl_df\n",
    "\n",
    "\n",
    "pred_round_results['result'] = np.where(pred_round_results['homeTeamScore.matchScore.totalScore']>pred_round_results['awayTeamScore.matchScore.totalScore'],1,0)\n",
    "\n",
    "actual_results = pred_round_results[['match.homeTeam.name','match.awayTeam.name','round.roundNumber','homeTeamScore.matchScore.totalScore','awayTeamScore.matchScore.totalScore','result']]\n",
    "\n",
    "df_next_games_teams = pd.merge(df_next_games_teams, actual_results, on=['match.homeTeam.name', 'match.awayTeam.name'])\n",
    "\n",
    "df_next_games_teams['score_1'] = 0.0\n",
    "df_next_games_teams['score_2'] = 0.0\n",
    "df_next_games_teams['score_3'] = 0.0\n",
    "\n",
    "for i in range(len(df_next_games_teams)):\n",
    "\n",
    "    p = df_next_games_teams['pred_home_prob'].values[i] \n",
    "    q = df_next_games_teams['pred_home_prob'].values[i] \n",
    "\n",
    "\n",
    "    if p > 0.68:\n",
    "        p = 0.68\n",
    "    elif p < 0.32:\n",
    "        p = 0.32\n",
    "\n",
    "    #if q > 0.8:\n",
    "    #    q = 0.8\n",
    "    #elif q < 0.2:\n",
    "    #    q = 0.2\n",
    "\n",
    "\n",
    "\n",
    "    if df_next_games_teams['homeTeamScore.matchScore.totalScore'].values[i] == df_next_games_teams['awayTeamScore.matchScore.totalScore'].values[i]:\n",
    "        df_next_games_teams['score_1'].values[i] = 1.0 + 0.5 * np.log2(p*(1-p))\n",
    "        df_next_games_teams['score_2'].values[i] = 1.0 + 0.5 * np.log2(p*(1-p))\n",
    "        df_next_games_teams['score_3'].values[i] = 1.0 + 0.5 * np.log2(q*(1-q))\n",
    "\n",
    "    elif (df_next_games_teams['pred_home_result'].values[i] == df_next_games_teams['result'].values[i]):\n",
    "        df_next_games_teams['score_1'].values[i] = 1.0 + np.log2(p)\n",
    "        if df_next_games_teams['pred_home_result'].values[i] == 1:\n",
    "            df_next_games_teams['score_2'].values[i] = 1.0 + np.log2(p)\n",
    "            df_next_games_teams['score_3'].values[i] = 1.0 + np.log2(q)\n",
    "        elif df_next_games_teams['pred_home_result'].values[i] == 0:\n",
    "            df_next_games_teams['score_2'].values[i] = 1.0 + np.log2(1.0-p)\n",
    "            df_next_games_teams['score_3'].values[i] = 1.0 + np.log2(1.0-q)\n",
    "\n",
    "    elif df_next_games_teams['pred_home_result'].values[i] != df_next_games_teams['result'].values[i]:\n",
    "        df_next_games_teams['score_1'].values[i] = 1.0 + np.log2(1.0 - p)\n",
    "\n",
    "        if df_next_games_teams['pred_home_result'].values[i] == 1:\n",
    "            df_next_games_teams['score_2'].values[i] = 1.0 + np.log2(1.0 - p)\n",
    "            df_next_games_teams['score_3'].values[i] = 1.0 + np.log2(1.0 - q)\n",
    "        elif df_next_games_teams['pred_home_result'].values[i] == 0:\n",
    "            df_next_games_teams['score_2'].values[i] = 1.0 + np.log2(1.0-(1.0-p))\n",
    "            df_next_games_teams['score_3'].values[i] = 1.0 + np.log2(1.0-(1.0-q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d0d80be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.16838487972509"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8153008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99999991e-01, 9.14510215e-09],\n",
       "       [9.32716449e-01, 6.72835508e-02],\n",
       "       [1.87873193e-01, 8.12126807e-01],\n",
       "       [9.99999997e-01, 2.64077854e-09],\n",
       "       [2.11089101e-01, 7.88910899e-01],\n",
       "       [9.99999787e-01, 2.13262686e-07],\n",
       "       [9.99878056e-01, 1.21944432e-04],\n",
       "       [9.99852726e-01, 1.47274098e-04],\n",
       "       [9.99966290e-01, 3.37098785e-05]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "193f1bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.730071339529514\n",
      "-2.5323171842215024\n",
      "-inf\n"
     ]
    }
   ],
   "source": [
    "print(df_next_games_teams['score_1'].sum())\n",
    "print(df_next_games_teams['score_2'].sum())\n",
    "print(df_next_games_teams['score_3'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "799de501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match.homeTeam.name</th>\n",
       "      <th>match.awayTeam.name</th>\n",
       "      <th>venue.name</th>\n",
       "      <th>round.year</th>\n",
       "      <th>round.roundNumber_x</th>\n",
       "      <th>match.matchId</th>\n",
       "      <th>train_data</th>\n",
       "      <th>pred_home_result</th>\n",
       "      <th>pred_home_prob</th>\n",
       "      <th>enter_tips</th>\n",
       "      <th>round.roundNumber_y</th>\n",
       "      <th>homeTeamScore.matchScore.totalScore</th>\n",
       "      <th>awayTeamScore.matchScore.totalScore</th>\n",
       "      <th>result</th>\n",
       "      <th>score_1</th>\n",
       "      <th>score_2</th>\n",
       "      <th>score_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brisbane Lions</td>\n",
       "      <td>Collingwood</td>\n",
       "      <td>Gabba</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>pick Collingwood with p=1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>98</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>0.443607</td>\n",
       "      <td>-0.643856</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>North Melbourne</td>\n",
       "      <td>Western Bulldogs</td>\n",
       "      <td>Marvel Stadium</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.067</td>\n",
       "      <td>pick Western Bulldogs with p=0.933</td>\n",
       "      <td>5</td>\n",
       "      <td>71</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.643856</td>\n",
       "      <td>0.443607</td>\n",
       "      <td>0.899949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>West Coast Eagles</td>\n",
       "      <td>Sydney Swans</td>\n",
       "      <td>Optus Stadium</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.812</td>\n",
       "      <td>pick West Coast Eagles with p=0.812</td>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.643856</td>\n",
       "      <td>-0.643856</td>\n",
       "      <td>-1.411195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>St Kilda</td>\n",
       "      <td>Gold Coast Suns</td>\n",
       "      <td>Marvel Stadium</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>pick Gold Coast Suns with p=1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>87</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0.443607</td>\n",
       "      <td>-0.643856</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelaide Crows</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>Adelaide Oval</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.789</td>\n",
       "      <td>pick Adelaide Crows with p=0.789</td>\n",
       "      <td>5</td>\n",
       "      <td>101</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.443607</td>\n",
       "      <td>0.443607</td>\n",
       "      <td>0.658097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Melbourne</td>\n",
       "      <td>GWS Giants</td>\n",
       "      <td>MCG</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>pick GWS Giants with p=1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0.443607</td>\n",
       "      <td>-0.643856</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Carlton</td>\n",
       "      <td>Port Adelaide</td>\n",
       "      <td>MCG</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>pick Port Adelaide with p=1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>94</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>0.443607</td>\n",
       "      <td>-0.643856</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Essendon</td>\n",
       "      <td>Fremantle</td>\n",
       "      <td>Marvel Stadium</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>pick Fremantle with p=1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>59</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.643856</td>\n",
       "      <td>0.443607</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hawthorn</td>\n",
       "      <td>Geelong Cats</td>\n",
       "      <td>MCG</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>pick Geelong Cats with p=1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>92</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>0.443607</td>\n",
       "      <td>-0.643856</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  match.homeTeam.name match.awayTeam.name      venue.name  round.year  \\\n",
       "0      Brisbane Lions         Collingwood           Gabba        2022   \n",
       "1     North Melbourne    Western Bulldogs  Marvel Stadium        2022   \n",
       "2   West Coast Eagles        Sydney Swans   Optus Stadium        2022   \n",
       "3            St Kilda     Gold Coast Suns  Marvel Stadium        2022   \n",
       "4      Adelaide Crows            Richmond   Adelaide Oval        2022   \n",
       "5           Melbourne          GWS Giants             MCG        2022   \n",
       "6             Carlton       Port Adelaide             MCG        2022   \n",
       "7            Essendon           Fremantle  Marvel Stadium        2022   \n",
       "8            Hawthorn        Geelong Cats             MCG        2022   \n",
       "\n",
       "   round.roundNumber_x  match.matchId  train_data  pred_home_result  \\\n",
       "0                    5              0           0                 0   \n",
       "1                    5              1           0                 0   \n",
       "2                    5              2           0                 1   \n",
       "3                    5              3           0                 0   \n",
       "4                    5              4           0                 1   \n",
       "5                    5              5           0                 0   \n",
       "6                    5              6           0                 0   \n",
       "7                    5              7           0                 0   \n",
       "8                    5              8           0                 0   \n",
       "\n",
       "   pred_home_prob                           enter_tips  round.roundNumber_y  \\\n",
       "0           0.000          pick Collingwood with p=1.0                    5   \n",
       "1           0.067   pick Western Bulldogs with p=0.933                    5   \n",
       "2           0.812  pick West Coast Eagles with p=0.812                    5   \n",
       "3           0.000      pick Gold Coast Suns with p=1.0                    5   \n",
       "4           0.789     pick Adelaide Crows with p=0.789                    5   \n",
       "5           0.000           pick GWS Giants with p=1.0                    5   \n",
       "6           0.000        pick Port Adelaide with p=1.0                    5   \n",
       "7           0.000            pick Fremantle with p=1.0                    5   \n",
       "8           0.000         pick Geelong Cats with p=1.0                    5   \n",
       "\n",
       "   homeTeamScore.matchScore.totalScore  awayTeamScore.matchScore.totalScore  \\\n",
       "0                                   98                                   91   \n",
       "1                                   71                                  139   \n",
       "2                                   58                                  121   \n",
       "3                                   87                                   61   \n",
       "4                                  101                                   82   \n",
       "5                                  120                                   53   \n",
       "6                                   94                                   91   \n",
       "7                                   59                                  107   \n",
       "8                                   92                                   80   \n",
       "\n",
       "   result   score_1   score_2   score_3  \n",
       "0       1  0.443607 -0.643856      -inf  \n",
       "1       0 -0.643856  0.443607  0.899949  \n",
       "2       0 -0.643856 -0.643856 -1.411195  \n",
       "3       1  0.443607 -0.643856      -inf  \n",
       "4       1  0.443607  0.443607  0.658097  \n",
       "5       1  0.443607 -0.643856      -inf  \n",
       "6       1  0.443607 -0.643856      -inf  \n",
       "7       0 -0.643856  0.443607  1.000000  \n",
       "8       1  0.443607 -0.643856      -inf  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_next_games_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b26727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459c4754",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
